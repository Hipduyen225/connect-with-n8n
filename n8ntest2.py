import openai
import pinecone
import uuid
import numpy as np
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from datetime import datetime
import faiss
import streamlit as st

# C·∫•u h√¨nh OpenAI v√† Pinecone
openai.api_key = "YOUR_OPENAI_API_KEY"  # ƒê·∫£m b·∫£o r·∫±ng b·∫°n ƒë√£ c√≥ API key c·ªßa OpenAI

# Kh·ªüi t·∫°o Pinecone v·ªõi c√°ch m·ªõi
from pinecone import Pinecone, ServerlessSpec

pc = Pinecone(
    api_key="YOUR_PINECONE_API_KEY"
)

# Ki·ªÉm tra n·∫øu index kh√¥ng c√≥ s·∫µn, t·∫°o m·ªõi
index_name = "cvdataset"  # T√™n ch·ªâ m·ª•c Pinecone c·ªßa b·∫°n
if index_name not in pc.list_indexes().names():
    pc.create_index(
        name=index_name,
        dimension=1536,  # ƒê·∫£m b·∫£o dimension ph√π h·ª£p v·ªõi embeddings c·ªßa b·∫°n
        metric="euclidean",  # B·∫°n c≈©ng c√≥ th·ªÉ d√πng 'cosine' ho·∫∑c 'dotproduct'
        spec=ServerlessSpec(
            cloud="aws",
            region="us-west-2"
        )
    )

# K·∫øt n·ªëi v·ªõi Pinecone
index = pc[index_name]

# T·∫°o session ID duy nh·∫•t cho m·ªói phi√™n l√†m vi·ªác
def generate_session_id():
    return str(uuid.uuid4())

# ƒê·ªçc v√† tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file PDF
def read_pdfs(pdf_files):
    text = ""
    for pdf in pdf_files:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text

# Chia nh·ªè vƒÉn b·∫£n n·∫øu qu√° d√†i (split)
def split_text(text, chunk_size=8000):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=200)
    return text_splitter.split_text(text)

# T·∫°o embedding t·ª´ vƒÉn b·∫£n b·∫±ng OpenAI
def create_embedding_from_text(text):
    response = openai.Embedding.create(
        model="text-embedding-ada-002",  # Ho·∫∑c m√¥ h√¨nh embedding kh√°c b·∫°n mu·ªën s·ª≠ d·ª•ng
        input=text
    )
    embeddings = response['data'][0]['embedding']
    return np.array(embeddings)

# Ch√®n d·ªØ li·ªáu v√†o Pinecone
def upload_to_pinecone(file_name, content, embeddings):
    metadata = {
        "file_name": file_name,
        "content": content[:500]  # Tr√≠ch xu·∫•t ph·∫ßn ƒë·∫ßu c·ªßa n·ªôi dung ƒë·ªÉ l√†m metadata
    }

    # T·∫°o vector cho file v√† ƒë∆∞a v√†o Pinecone
    upsert_response = index.upsert(
        vectors=[(str(uuid.uuid4()), embeddings.tolist(), metadata)]
    )
    return upsert_response

# S·ª≠ d·ª•ng FAISS ƒë·ªÉ t·∫°o vector store
def create_faiss_index(embeddings_list):
    dimension = len(embeddings_list[0])
    index = faiss.IndexFlatL2(dimension)  # Using L2 (Euclidean) distance
    faiss_index = faiss.IndexIDMap(index)
    
    ids = np.array([i for i in range(len(embeddings_list))])
    embeddings = np.vstack(embeddings_list)
    faiss_index.add_with_ids(embeddings, ids)
    
    return faiss_index

# L·∫•y input ng∆∞·ªùi d√πng v√† x·ª≠ l√Ω
def user_input(user_question, pdf_docs, conversation_history):
    if pdf_docs is None:
        st.warning("Please upload PDF files before processing.")
        return

    text_chunks = split_text(get_pdf_text(pdf_docs), model_name="OpenAI")
    embeddings_list = []
    for chunk in text_chunks:
        embeddings = create_embedding_from_text(chunk)
        embeddings_list.append(embeddings)

    # Ch√®n v√†o Pinecone
    for embeddings, chunk in zip(embeddings_list, text_chunks):
        response = upload_to_pinecone(file_name="Uploaded PDF", content=chunk, embeddings=embeddings)
        st.success(f"‚úÖ File processed and uploaded to Pinecone successfully!")

    # T·∫°o FAISS index t·ª´ embeddings
    faiss_index = create_faiss_index(embeddings_list)

    # Tr·∫£ v·ªÅ ph·∫£n h·ªìi cho c√¢u h·ªèi ng∆∞·ªùi d√πng
    question_embedding = create_embedding_from_text(user_question)
    D, I = faiss_index.search(np.array([question_embedding]), k=5)  # L·∫•y 5 c√¢u tr·∫£ l·ªùi g·∫ßn nh·∫•t

    # T·∫°o c√¢u tr·∫£ l·ªùi d·ª±a tr√™n c√¢u tr·∫£ l·ªùi g·∫ßn nh·∫•t
    relevant_docs = [text_chunks[i] for i in I[0]]
    answer = " ".join(relevant_docs)

    conversation_history.append((user_question, answer, "OpenAI", datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
    
    st.write("Answer: ", answer)

# H√†m ƒë·ªÉ l·∫•y vƒÉn b·∫£n t·ª´ PDF
def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text

# H√†m ch√≠nh ƒë·ªÉ hi·ªÉn th·ªã giao di·ªán v√† x·ª≠ l√Ω c√¢u h·ªèi ng∆∞·ªùi d√πng
def main():
    st.set_page_config(page_title="CV Recruitment AI", page_icon="üíº")
    st.header("üíº CV Recruitment AI Assistant")

    # L∆∞u tr·ªØ l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []

    model_name = st.sidebar.radio("Select the Model:", ("OpenAI"))

    # Ch·ªçn API Key
    api_key = st.sidebar.text_input("Enter your OpenAI API Key:")
    if not api_key:
        st.sidebar.warning("Please enter your OpenAI API Key to proceed.")
        return

    with st.sidebar:
        st.title("Menu:")
        pdf_docs = st.file_uploader("Upload your PDF Files and Click on the Submit & Process Button", accept_multiple_files=True)
        
        if st.button("Submit & Process"):
            if pdf_docs:
                with st.spinner("Processing..."):
                    st.success("Done")
            else:
                st.warning("Please upload PDF files before processing.")

    user_question = st.text_input("Ask a Question from the PDF Files")

    if user_question:
        user_input(user_question, pdf_docs, st.session_state.conversation_history)

if __name__ == "__main__":
    main()